{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75bb5817",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f15476",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0296a957",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a spark session (which will run spark jobs)\n",
    "spark = (\n",
    "    SparkSession.builder.appName(\"MAST30034 Project 1\")\n",
    "    .config(\"spark.sql.repl.eagerEval.enabled\", True) \n",
    "    .config(\"spark.sql.parquet.cacheMetadata\", \"true\")\n",
    "    .config(\"spark.sql.session.timeZone\", \"Etc/UTC\")\n",
    "    .config(\"spark.driver.memory\", \"3g\")\n",
    "    .config(\"spark.executer.memory\", \"4g\")\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "821538ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the downloaded data \n",
    "sdf_all = spark.read.parquet('../data/raw/tlc_data/')\n",
    "sdf_all.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6eca61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf_all.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8052d871",
   "metadata": {},
   "source": [
    "### Feature Filtering\n",
    "Irrelevant attributes are removed from the dataset. The following attributes are retained:\n",
    "- pickup_datetime\n",
    "- PULocationID\n",
    "- DOLocationID\n",
    "- trip_miles\n",
    "- congestion_surcharge\n",
    "- trip_time (response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8171c046",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only keep relevant features\n",
    "sdf_all = sdf_all.select('pickup_datetime', 'PULocationID', 'DOLocationID', 'trip_miles', 'congestion_surcharge', 'trip_time')\n",
    "sdf_all.show(1, vertical=True, truncate=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1af48285",
   "metadata": {},
   "source": [
    "### Outliers Removal\n",
    "- Trips that have taken more than 5 hours or less than 2 minutes are removed from dataset.\n",
    "- There are a large number of trips that have zero 'trip_miles', indicating that the vehicles has not moved at all. These records are removed.\n",
    "- Trips with 'Unknown' pickup or dropoff location (LocationID is either 264 or 265) are removed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab315889",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the number of outliers\n",
    "print(\"Number of trips has trip duration greater than 5 hours:\", sdf_all.filter(F.col('trip_time') > 5*60*60).count())\n",
    "print(\"Number of trips has trip duration less than 2 minutes:\", sdf_all.filter(F.col('trip_time') < 2*60).count())\n",
    "print(\"Number of trips with 0 distance\", sdf_all.filter(F.col('trip_miles') <= 0).count())\n",
    "print(\"Number of trips with unknown pickup/drop-off location:\", sdf_all.filter((F.col('PULocationID') == 265) |\n",
    "     (F.col('PULocationID') == 264) | (F.col('DOLocationID') == 265) | (F.col('DOLocationID') == 264)).count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74fd79fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out all outliers\n",
    "sdf_all = sdf_all.filter((F.col('trip_time') <= 5*60*60) & (F.col('trip_time') > 2*60) & (F.col('trip_miles') > 0) &\n",
    "                          (F.col('PULocationID') <= 263) & (F.col('DOLocationID') <= 263))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd09fb1",
   "metadata": {},
   "source": [
    "### Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6accc547",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if there are missing values for each attributes\n",
    "features = ['pickup_datetime', 'PULocationID', 'DOLocationID', 'trip_miles', 'congestion_surcharge', 'trip_time']\n",
    "for attr in features:\n",
    "    num_missing = sdf_all.filter(F.col(attr).isNull()).count()\n",
    "    print(f\"There are {num_missing} missing values for feature {attr}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b571dce",
   "metadata": {},
   "source": [
    "Condsidering the large size of the dataset, it is reasonable to discard trips where 'congestion_surcharge' equals to null."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95769f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove records with missing values\n",
    "sdf_all = sdf_all.filter(~ F.col(\"congestion_surcharge\").isNull())\n",
    "sdf_all.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77203243",
   "metadata": {},
   "source": [
    "### Preliminary Feature Engineering\n",
    "- 'day of week', 'hour of day' and 'month,day' are extracted from 'pickup_datetime'.\n",
    "\n",
    "- Convert columns \"PULocationID\" and \"DOLocationID\" to integers.\n",
    "\n",
    "- Since the amount of surcharge only depends on the type of vehicle and is considered to have little correlation with trip time, it is replaced by an binary feature 'congestion_zone' which suggests whether a trip passes through the Congestion Zone. \n",
    "\n",
    "- Combine the dataset with external weather data based on date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f68b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract hour of day and day of week from pickup datetime\n",
    "sdf_all = sdf_all.withColumn(\"day_of_week\", F.date_format('pickup_datetime', 'EEEE'))\\\n",
    "                 .withColumn(\"hour_of_day\", F.hour(F.col('pickup_datetime')))\\\n",
    "                 .withColumn(\"month-day\", F.date_format('pickup_datetime','MM,dd'))\n",
    "    \n",
    "# convert type of data entries from long to int\n",
    "for field in ('PU', 'DO'):\n",
    "    field = f'{field}LocationID'\n",
    "    sdf_all = sdf_all.withColumn(\n",
    "        field,\n",
    "        F.col(field).cast('INT')\n",
    "    )\n",
    "\n",
    "# replace continous attribute \"congestion_surcharge\" with binary attribute \"congestion_zone\" \n",
    "sdf_all = sdf_all.withColumn('congestion_zone', (F.col('congestion_surcharge') > 0).cast('BOOLEAN'))\n",
    "sdf_all = sdf_all.drop(\"congestion_surcharge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "905afd3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the weather dataset\n",
    "weather_sdf = spark.read.option(\"header\", \"true\").csv(\"../data/raw/weather_data/weather.csv\")\n",
    "weather_sdf.limit(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5501b282",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_sdf.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72718629",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert all columns except \"Month,Day\" to float\n",
    "cols = [\"Temperature (F)\", \"Dew Point (F)\", \"Humidity (%)\", \"Wind Speed (mph)\", \"Pressure (in)\", \"Precipitation (in)\"]\n",
    "for col in cols:\n",
    "    weather_sdf = weather_sdf.withColumn(col, weather_sdf[col].cast('float'))\n",
    "\n",
    "weather_sdf.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b73c1077",
   "metadata": {},
   "outputs": [],
   "source": [
    "# join the weather dataset with for-hire vehicles trip data\n",
    "sdf_all = sdf_all.join(weather_sdf, sdf_all[\"month-day\"] == weather_sdf[\"Month,Day\"], 'left')\n",
    "\n",
    "# example of record after feature engineering\n",
    "sdf_all.show(1, vertical=True, truncate=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f2048d9",
   "metadata": {},
   "source": [
    "### Train Test Split\n",
    "To avoid data leakage, the dataset is divided into Train (Feb 2019 - May 2019 inclusive) and Test (Jun 2019 - Jul 2019 inclusive) sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db0950ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train/test split\n",
    "train_sdf = sdf_all.filter(F.col(\"pickup_datetime\").between('2019-02-01 00:00:00', '2019-5-31 23:59:59'))\n",
    "test_sdf = sdf_all.filter(F.col(\"pickup_datetime\").between('2019-06-01 00:00:00', '2019-07-31 23:59:59'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24983c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove attributes \"pickup_datetime\" and \"month-day\" from the both dataframes\n",
    "train_sdf = train_sdf.drop(\"pickup_datetime\", \"month-day\", \"Month,Day\")\n",
    "test_sdf = test_sdf.drop(\"pickup_datetime\", \"month-day\", \"Month,Day\")\n",
    "\n",
    "print(\"Number of instances in training set:\", train_sdf.count())\n",
    "print(\"Number of instances in test set:\", test_sdf.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bed5a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save train/test sets\n",
    "train_sdf.write.mode('overwrite').parquet('../data/curated/train')\n",
    "test_sdf.write.mode('overwrite').parquet('../data/curated/test')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95b91047",
   "metadata": {},
   "source": [
    "### Sampling Data for Visualisations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b26e748f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sampling data for future visualisations\n",
    "SAMPLE_SIZE = 0.005\n",
    "sample_sdf = train_sdf.sample(SAMPLE_SIZE, seed=0)\n",
    "print(\"Number of instances in sample dataset:\", sample_sdf.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a4854ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save sample data\n",
    "sample_sdf.write.mode('overwrite').parquet(\"../data/curated/sample_data\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "703e593df40508a60fa363339ca2bbb5bae045b0a530fb0e89bc3e7c255f1da9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
