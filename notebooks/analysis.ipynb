{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.stat import Correlation\n",
    "from statsmodels.formula.api import ols\n",
    "import statsmodels.api as sm\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import folium\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('darkgrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a spark session\n",
    "spark = (\n",
    "    SparkSession.builder.appName(\"MAST30034 Project 1 analysis\")\n",
    "    .config(\"spark.sql.repl.eagerEval.enabled\", True) \n",
    "    .config(\"spark.sql.parquet.cacheMetadata\", \"true\")\n",
    "    .config(\"spark.sql.session.timeZone\", \"Etc/UTC\")\n",
    "    .config(\"spark.driver.memory\", \"3g\")\n",
    "    .config(\"spark.executer.memory\", \"4g\")\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read training, test and sample dataset\n",
    "train_sdf = spark.read.parquet('../data/curated/train')\n",
    "test_sdf = spark.read.parquet(\"../data/curated/test\")\n",
    "sample_df = pd.read_parquet('../data/curated/sample_data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution of Trip Time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# distribution plot of the target variable \"trip time\"\n",
    "sns.displot(sample_df[\"trip_time\"])\n",
    "plt.title(\"Distribution of Trip Time\", fontsize=14)\n",
    "plt.xlabel(\"Trip Time (s)\", fontsize=12)\n",
    "plt.ylabel(\"Count\", fontsize=12)\n",
    "plt.ticklabel_format(style='sci', axis='y')\n",
    "plt.savefig(\"../plots/trip_time_dist.png\", bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply log transformation on trip time\n",
    "log_time = np.log(sample_df[\"trip_time\"])\n",
    "sns.displot(log_time, kde=True)\n",
    "plt.title(\"Distribution of Log Transformed Trip Time\", fontsize=14)\n",
    "plt.xlabel(\"Log transformed trip time (s)\", fontsize=12)\n",
    "plt.ylabel(\"Count\", fontsize=12)\n",
    "plt.savefig(\"../plots/log_trip_time_dist.png\", bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Geospatial Visualisations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sf stands for shape file\n",
    "sf = gpd.read_file(\"../data/raw/taxi_zones/taxi_zones.shp\")\n",
    "zones = pd.read_csv(\"../data/raw/taxi_zones/taxi+_zone_lookup.csv\")\n",
    "\n",
    "# Convert the geometry shape to latitude and longitude\n",
    "sf['geometry'] = sf['geometry'].to_crs(\"+proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs\")\n",
    "\n",
    "gdf = gpd.GeoDataFrame(\n",
    "    pd.merge(zones, sf, on='LocationID', how='inner')\n",
    ")\n",
    "\n",
    "# create a JSON \n",
    "geoJSON = gdf[['LocationID', 'geometry']].drop_duplicates('LocationID').to_json()\n",
    "\n",
    "# derive zone centroids \n",
    "gdf['centroid'] = gdf['geometry'].apply(lambda x: (x.centroid.y, x.centroid.x))\n",
    "gdf[['Zone', 'LocationID', 'centroid']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute median trip time of the whole training data in each pickup/dropoff location\n",
    "pickup_median_time = train_sdf.groupBy(\"PULocationID\")\\\n",
    "                              .agg(F.percentile_approx(\"trip_time\", 0.5)\\\n",
    "                              .alias(\"median_trip_time\"))\\\n",
    "                              .toPandas()\n",
    "dropoff_median_time = train_sdf.groupBy(\"DOLocationID\")\\\n",
    "                               .agg(F.percentile_approx(\"trip_time\", 0.5)\\\n",
    "                               .alias(\"median_trip_time\"))\\\n",
    "                               .toPandas()\n",
    "\n",
    "# join the computed dataframe with geo dataframe\n",
    "pickup_df = pickup_median_time.merge(gdf[['LocationID', 'geometry']], left_on='PULocationID', right_on='LocationID') \\\n",
    "                              .drop('LocationID', axis=1)\n",
    "\n",
    "dropoff_df = dropoff_median_time.merge(gdf[['LocationID', 'geometry']], left_on='DOLocationID', right_on='LocationID') \\\n",
    "                                .drop('LocationID', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function plots a choropleth map for a given dataframe and legend name\n",
    "def draw_map(df, columns, legend_name):\n",
    "    map = folium.Map(location=[40.73, -73.74], width=600, height=500, tiles=\"cartodbpositron\", zoom_start=10)\n",
    "\n",
    "    c = folium.Choropleth(\n",
    "        geo_data=geoJSON, # geoJSON \n",
    "        name='choropleth', \n",
    "        data=df.reset_index(), # data source\n",
    "        columns=columns, # the columns required\n",
    "        key_on='properties.LocationID', # this is from the geoJSON's properties\n",
    "        fill_color='YlOrRd', # color scheme\n",
    "        line_opacity=0.1,\n",
    "        fill_opacity=0.7,\n",
    "        legend_name=legend_name\n",
    "    )\n",
    "\n",
    "    c.add_to(map)\n",
    "\n",
    "    # mark all the airports on the map\n",
    "    for zone_name, coord in gdf.loc[gdf['Zone'].str.contains('Airport'), ['Zone', 'centroid']].values:\n",
    "        map.add_child(\n",
    "            folium.Marker(location=coord, popup=zone_name, icon=folium.Icon(color='blue', icon='glyphicon-plane'))\n",
    "        )\n",
    "\n",
    "    return map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the map of median trip time for each pickup location\n",
    "pickup_map = draw_map(pickup_df, ['PULocationID','median_trip_time'], \"Median Trip Duration (second)\")\n",
    "pickup_map.save('../plots/pickup_location_vs_median_trip_time_map.html')\n",
    "pickup_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the map of median trip time of each dropoff location\n",
    "dropoff_map = draw_map(dropoff_df, ['DOLocationID','median_trip_time'], \"Median Trip Duration (second)\")\n",
    "dropoff_map.save('../plots/dropoff_location_vs_median_trip_time_map.html')\n",
    "dropoff_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be seen that trips to or from the three airports usually take longer. Also, trips within Manhattan generally have longer duration.\n",
    "Therefore, we decide to create new binary attributes that indicate whether the trip is within Manhattan or is an airport trip."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# observe the location id of airports\n",
    "gdf.loc[gdf['Zone'].str.contains('Airport'), ['LocationID', 'Zone']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_location_attribute(sdf):\n",
    "    # create new attributes that indicates whether a trip is to or from the three airports\n",
    "    sdf = sdf.withColumn('Newark_trip', ((sdf['PULocationID'] == 1) | (sdf['DOLocationID'] == 1)).cast('BOOLEAN'))\n",
    "    sdf = sdf.withColumn('JFK_trip', ((sdf['PULocationID'] == 132) | (sdf['DOLocationID'] == 132)).cast('BOOLEAN'))\n",
    "    sdf = sdf.withColumn('LaGuardia_trip', ((sdf['PULocationID'] == 138) | (sdf['DOLocationID'] == 138)).cast('BOOLEAN'))\n",
    "    \n",
    "    # create a new attribute that indicates whether a trip is within Manhattan borough\n",
    "    manhattan_ID = gdf.loc[gdf['Borough'].str.contains('Manhattan'), 'LocationID'].values.tolist()\n",
    "    sdf = sdf.withColumn('Manhattan_trip', ((sdf['PULocationID'].isin(manhattan_ID)) | (sdf['DOLocationID'].isin(manhattan_ID))).cast('BOOLEAN'))\n",
    "    return sdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace picup/dropoff location id with four binary attributes\n",
    "train_sdf = add_location_attribute(train_sdf)\n",
    "train_sdf = train_sdf.drop(\"PULocationID\", \"DOLocationID\")\n",
    "\n",
    "test_sdf = add_location_attribute(test_sdf)\n",
    "test_sdf = test_sdf.drop(\"PULocationID\", \"DOLocationID\")\n",
    "\n",
    "train_sdf.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categoriacal Variables\n",
    "- Anova Test  \n",
    "The normality assumption for ANOVA states that the distribution of Y within each group is normally distributed. Hence, log transformation is applied to trip time before doing ANOVA tests.  \n",
    "\n",
    "- Line plot   \n",
    "The median trip time of the whole training data is computed and used to demonstrate the relationship between day of week and trip time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply log transformation\n",
    "sample_df['trip_time'] = np.log(sample_df['trip_time'])\n",
    "\n",
    "# fit a ols model with three discrete attributes\n",
    "ols_model = ols(\n",
    "    formula=\"trip_time ~ C(day_of_week) + C(congestion_zone)\",\n",
    "    data=sample_df\n",
    ").fit()\n",
    "\n",
    "# display anova table of the fitted model\n",
    "table = sm.stats.anova_lm(ols_model, typ=2)\n",
    "pd.set_option('display.float_format', '{:.2e}'.format)\n",
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute median trip time in each weekday\n",
    "trip_time_vs_day = train_sdf.groupBy(\"day_of_week\")\\\n",
    "                            .agg(F.percentile_approx(\"trip_time\", 0.5)\\\n",
    "                            .alias(\"median_trip_time\"))\\\n",
    "                            .toPandas() \n",
    "                            \n",
    "# change the order of the dataframe: Monday to Sunday\n",
    "order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "trip_time_vs_day = trip_time_vs_day.set_index('day_of_week').reindex(order).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# line plot of median trip time versus weekday\n",
    "sns.lineplot(data=trip_time_vs_day, x=\"day_of_week\", y=\"median_trip_time\")\n",
    "plt.title(\"Median Trip Duration in Different Days of a Week\", fontsize=14)\n",
    "plt.xticks(rotation=30, fontsize=12)\n",
    "plt.xlabel(\"\")\n",
    "plt.ylabel(\"Median trip duration (s)\", fontsize=13)\n",
    "plt.savefig(\"../plots/median_trip_time_vs_day.png\", bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Continuous Variables\n",
    "- Correlation heatmap   \n",
    "Pearson correlations between trip time and all continous attributes are calculated and plotted as a heatmap.\n",
    "\n",
    "- Line plot  \n",
    "The median trip time in different hours of a day is computed and used to demonstrate the relationship between hour of day and trip time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot a correlation heatmap between continuous attributes of the full training set\n",
    "CORR_COLS = ['trip_time', 'trip_miles', 'Temperature (F)', 'Dew Point (F)', 'hour_of_day',\n",
    "'Humidity (%)', 'Wind Speed (mph)', 'Pressure (in)', 'Precipitation (in)']\n",
    "\n",
    "features = \"correlation_features\"\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=CORR_COLS, # input names (can be list of fields)\n",
    "    outputCol=features # output name (single vector output)\n",
    ")\n",
    "\n",
    "# transform the features \n",
    "feature_vector = assembler.transform(train_sdf.dropna('any')).select(features)\n",
    "corr_matrix_dense = Correlation.corr(feature_vector, features)\n",
    "corr_matrix = corr_matrix_dense.collect()[0][0].toArray().tolist()\n",
    "\n",
    "df_corr = pd.DataFrame(corr_matrix, index=CORR_COLS, columns=CORR_COLS)\n",
    "df_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot correlation heatmap\n",
    "plt.figure(figsize = (10,6))\n",
    "sns.set(font_scale=1.1) \n",
    "labels = ['Trip time', 'Trip miles', 'Temperature', 'Dew point', 'Hour of Day', 'Humidity', 'Wind speed', 'Pressure ', 'Precipitation']\n",
    "sns.heatmap(df_corr, annot=True, xticklabels=labels, yticklabels=labels)\n",
    "plt.title('Pearson Correlation Metric For Continuous Variables', fontsize=15)\n",
    "plt.savefig(\"../plots/corr_matrix.png\", bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute median trip time in each hour of a day\n",
    "trip_time_vs_hour = train_sdf.groupBy(\"hour_of_day\")\\\n",
    "                             .agg(F.percentile_approx(\"trip_time\", 0.5)\\\n",
    "                             .alias(\"median_trip_time\"))\\\n",
    "                             .toPandas() \n",
    "\n",
    "# line plot of median trip time versus hour of day\n",
    "sns.lineplot(data=trip_time_vs_hour, x=\"hour_of_day\", y=\"median_trip_time\")\n",
    "plt.title(\"Median Trip Duration in Different Hours of a Day\", fontsize=14)\n",
    "plt.xlabel(\"Hour of day\", fontsize=13)\n",
    "plt.xticks(np.arange(0, 24, 3))\n",
    "plt.ylabel(\"Median trip duration (s)\", fontsize=13)\n",
    "plt.savefig(\"../plots/median_trip_time_vs_hour.png\", bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection \n",
    "According to the feature correlation obtained from the computation and analysis above, we decided to drop the attributes that have little contribution in explaining the response variable \"trip time\".  \n",
    "\n",
    "The following attributes are retained,  \n",
    "- Discrete attribute  \n",
    "    - JFK trip\n",
    "    - Newark trip\n",
    "    - LaGuardia trip\n",
    "    - Manhattan trip\n",
    "    - day of week\n",
    "    - congestion zone\n",
    "- Continuous attribute\n",
    "    - trip miles\n",
    "    - temperature\n",
    "    - hour of day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_attr = ['trip_miles', 'day_of_week', 'hour_of_day', 'JFK_trip', 'Newark_trip', 'LaGuardia_trip', 'Manhattan_trip',\n",
    "                'congestion_zone', 'Temperature (F)', 'trip_time']\n",
    "\n",
    "# feature selection on train and test data\n",
    "train_sdf = train_sdf.select(chosen_attr)\n",
    "test_sdf = test_sdf.select(chosen_attr)\n",
    "\n",
    "train_sdf.show(1, vertical=True, truncate=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save processed training and test data\n",
    "train_sdf.write.mode('overwrite').parquet('../data/curated/new_train')\n",
    "test_sdf.write.mode('overwrite').parquet('../data/curated/new_test')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "703e593df40508a60fa363339ca2bbb5bae045b0a530fb0e89bc3e7c255f1da9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
